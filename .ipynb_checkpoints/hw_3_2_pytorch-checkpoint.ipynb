{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cX_WL9cbbJas"
   },
   "source": [
    "# Домашнее задание 2.2\n",
    "\n",
    "В этом задании нужно:\n",
    "1. Написать свою сеть на Pytorch по варианту\n",
    "2. Обучить ее и сравнить результаты с дообученной сетью из зоопарка моделей\n",
    "3. Поставить ряд экспериментов, показывающих насколько гиперпараметры обучения влияют на результат"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qHaLl3E5cwy_"
   },
   "source": [
    "**Варианты архитектуры сверточной сети:**\n",
    "Вариант на ваш выбор - напишите его в конфу. Не более двух человек на один вариант\n",
    "1. Resnet v2\n",
    "2. Inception Google LeNet\n",
    "3. MobileNet v2\n",
    "4. SE Net\n",
    "5. DenseNet\n",
    "6. Conv Mixer\n",
    "7. EfficientNet v2 (Григорий Конюхов)\n",
    "8. NFNet\n",
    "9. Придуманная вами архитектура на ваш вкус."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x3IXrQYcU2LG"
   },
   "source": [
    "**Варианты оптимизатора:**\n",
    "Для дополнительных баллов, только один вариант на человека\n",
    "1. Sharpness Aware Optimization (+1.5 балл)\n",
    "2. Stachastic Average Gradients (+1.5 балл)\n",
    "3. Nesterov Accelerated Gradients (+1 балл)\n",
    "4. Large Batch Optimization, LAMB (+1 балл)\n",
    "5. Adan (+1 балл) (Григорий Конюхов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3bWCyebM5HCh"
   },
   "source": [
    "## Имплементация сети на Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8_rU_f5-5L3D"
   },
   "source": [
    "Здесь вы должны написать модель, выданную вам по варианту.\n",
    "Для этого нужно:\n",
    "1. Не забывать про использоватие блоков nn.Module, nn.Sequential, nn.ModuleList\n",
    "2. Использовать материалы из предыдущих семинаров\n",
    "\n",
    "В качестве примера ниже реализован макет для модели, состоящей из RepVGG-блоков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RjMhL5bcagsR"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tp_igxkE6BnN"
   },
   "outputs": [],
   "source": [
    "class RepVGGBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        # подготовка RepVGG блоков\n",
    "        self.identity = nn.BatchNorm2d(out_channels)\n",
    "        self.layer_3x3 = nn.Conv2d(in_channels, out_channels, 3, padding=1)\n",
    "        self.layer_1x1 = nn.Conv2d(in_channels, out_channels, 1)\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer_3x3(x) + self.layer_1x1(x) + self.identity(x)\n",
    "        x = self.act(x)\n",
    "        return x\n",
    "\n",
    "class RepVGG(nn.Module):\n",
    "    def __init__(self, num_blocks=4, width_multiplier=[1, 2, 4, 4], num_classes=10):\n",
    "        super().__init__()\n",
    "        assert len(width_multiplier) == num_blocks\n",
    "\n",
    "        self.first_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=8, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.repvgg_blocks = nn.Sequential(\n",
    "            # здесь происходит создание блоков\n",
    "        )\n",
    "\n",
    "        # в конце сверточных слоев ставим AdaptiveAvgPool2d\n",
    "        # и linear слой\n",
    "        self.gap = nn.AdaptiveAvgPool2d(output_size=1)\n",
    "        self.linear = nn.Linear(int(512 * width_multiplier[-1]), num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # forward основной модели\n",
    "        x = self.first_conv(x)\n",
    "        x = self.repvgg_blocks(x)\n",
    "        x = self.gap(x)\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kPncPqPp_A6a"
   },
   "outputs": [],
   "source": [
    "# если вы написали модель правильно\n",
    "# эта ячейка должна выполниться\n",
    "model = RepVGG()\n",
    "sample_tensor = torch.randn(1, 3, 32, 32)\n",
    "model(sample_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hLD8YPRH5UOS"
   },
   "source": [
    "## Обучение и подбор гиперпараметров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "plUS_5-X5YAh"
   },
   "source": [
    "Чтобы не писать собственный train loop, мы будем использовать Pytorch Lightning.   \n",
    "\n",
    "Это не самый лучший фреймворк для обучения - в нем множество багов, которые особенно любят проявлять себя в сложных моделях, обучаемых в low-precision с параллелизмом.  \n",
    "\n",
    "Но большая часть популярных фреймворков организована именно так - train loop скрыт от глаз пользователя. Поэтому полезно посмотреть это на таком простом примере, как Pytorch Lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PwIM9K5wBF5B"
   },
   "outputs": [],
   "source": [
    "! pip install pytorch_lightning >> None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Woi5D02x5Xac"
   },
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "\n",
    "class ConvModelPL(pl.LightningModule):\n",
    "  def __init__(self, model, lr, weight_decay):\n",
    "    super().__init__()\n",
    "    self.model = model\n",
    "    self.lr = lr\n",
    "    self.weight_decay = weight_decay\n",
    "\n",
    "  def training_step(self, batch, batch_idx):\n",
    "    # training_step определяет шаг в train loop\n",
    "    # forward модели и подсчет лосса\n",
    "    x, y = batch\n",
    "    # <your code here>\n",
    "    # по умолчанию логгируем в TensorBoard\n",
    "    self.log(\"train_loss\", loss)\n",
    "    return loss\n",
    "\n",
    "  def validation_step(self, batch, batch_idx):\n",
    "    x, y = batch\n",
    "    # соответсвенно, здесь выполняется шаг валидации\n",
    "    # тоже нужно сделать forward модели и подсчитать лосс\n",
    "    # но кроме этого - вычислить метрику\n",
    "    # <your code here>\n",
    "    self.log(\"val_loss\", loss)\n",
    "    return metric\n",
    "\n",
    "  def validation_epoch_end(self, validation_step_outputs):\n",
    "    # этот шаг выполняется в конце эпохи\n",
    "    # здесь мы усредним накопленную метрику\n",
    "    # и передадим ее в логгер\n",
    "    total_metric = torch.stack(validation_step_outputs).mean()\n",
    "    self.log(\"val_epoch_acc\", acc_epoch)\n",
    "\n",
    "\n",
    "  def configure_optimizers(self):\n",
    "      # здесь мы настраиваем оптимизатор\n",
    "      # вы можете сделать более сложную конфигурацию\n",
    "      optimizer = torch.optim.AdamW(self.parameters(), lr=self.lr, weight_decay=self.weight_decay,)\n",
    "      return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lNRIAatVCug5"
   },
   "outputs": [],
   "source": [
    "model = ConvNet()\n",
    "model_pl = ConvModelPL(model, lr=1e-4, weight_decay=1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y3CdP4tPC08O"
   },
   "source": [
    "Дальше создадим датасеты и даталоадеры.\n",
    "Опять же, вам нужно написать более точную конфигурацию: подобрать аугментации, batch_size, параметры даталоадера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ltfuDf8gCvL3"
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "batch_size = 32\n",
    "workers = 1\n",
    "\n",
    "# вспомните, что вы можете использовать не только аугментации из torchvision\n",
    "# но и из albumentations и, если уж совсем хотите заморочиться, nvidia dali\n",
    "transform = transforms.Compose(\n",
    "    # <your code here>\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "test_set = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "\n",
    "# есть несколько способов ускорения даталоадера\n",
    "\n",
    "# главный из них - ставить pin_memory, когда вы работаете с gpu\n",
    "# дело в том, что программы на host'е работает с логической памятью, которая называется paged memory,\n",
    "# она связана с физической с помощью таблицы - page table\n",
    "# когда физической памяти не хватает, страницы из page memory выгружаются (page out) на другие носители (например, на ssd)\n",
    "# получается, paged memory нестабильна и может быть разбросана по разным физическим устройствам\n",
    "# чтобы скопировать данные на device, сначала данные из paged memory копируются в page-locked memory,\n",
    "# и только затем на device\n",
    "# можно избежать такого: сразу выделять память в page-locked memory\n",
    "# именно это и делает аргумент pin_memory=True\n",
    "# https://developer.nvidia.com/blog/how-optimize-data-transfers-cuda-cc/\n",
    "\n",
    "# есть и другие способы - например, num_workers ~ числу ядер или половине от числа ядер\n",
    "\n",
    "# также если у вашего трейнлупа нет точек синхронизации (напимер, print, logging, перемещение на cpu)\n",
    "# то можно ставить data = data.to('cuda:0', non_blocking=True) при отправлении данных\n",
    "# https://discuss.pytorch.org/t/should-we-set-non-blocking-to-true/38234/3\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=workers)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IdHuE97-DHSj"
   },
   "outputs": [],
   "source": [
    "# а теперь можно запускать обучение и смотреть метрики и графики\n",
    "# просмотр графиков вы должны вставить сами\n",
    "device = 'cuda'\n",
    "\n",
    "trainer = pl.Trainer(limit_train_batches=100, max_epochs=20)\n",
    "trainer.fit(model_pl, train_loader, test_loader, accelerator=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aEUZsAL3GsML"
   },
   "source": [
    "После пробного обучения модели попробуем подобрать гиперпараметры и, если вы этого захотите, немного изменить архитектуру модели так, чтобы добиться более высокой метрики."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iOTbIAOwHakP"
   },
   "source": [
    "### Как проводить эксперименты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oXJjLoZXHeHZ"
   },
   "source": [
    "\"Neural net training is a leaky abstraction\" - Andrej Karpathy\n",
    "\n",
    "Знания теории, архитектур, оптимизаторов порой недостаточно для получения хорошей модели - значит, пришла пора подбора гиперпараметров.  \n",
    "В таких случаях может помочь не *model-centric*, а *data-centric* подход: переразметить данные, поменять аугментации, докинуть новые.\n",
    "\n",
    "**Но во всех этих случаях правильно организовать эксперименты**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YByhO57qIh34"
   },
   "source": [
    "**Перед началом:**\n",
    "Убедитесь, что у вас есть хороший и адекватный бейзлайн\n",
    "1. Сначала вместо самописных моделей берите архитектуры из известных репозиториев (torchvision, timm, mmdetection, huggingface etc)\n",
    "2. Эти архитектуры должны быть стандартными для вашей задачи. То есть, для задач компьютерного зрения (классификации, детекции, сегментации) - ResNet, для обработки языков - трансформер.\n",
    "3. Не придумывайте сложные пайплайны обучения - Adam + LR без расписания, предобработка входа - такая же как у предобученной модели\n",
    "4. Первые пробные запуски делайте на подвыборках, тестовых датасетах\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tdRq8GwXKLJU"
   },
   "source": [
    "**Снизьте число факторов влияния**:\n",
    "1. Баги могут быть в разных частях: в модели, обучении, загрузке данных, проверке качества\n",
    "2. Визуализируйте *все*: метрики, лоссы, градиенты, примеры работы модели, работу аугментаций\n",
    "3. Пишите unit-тесты. Даже небольшие!\n",
    "4. Сохраняйте чекпоинты. Не только best и last. Полезно брать чекпоинты каждые несколько итераций\n",
    "5. При проведении экспериментов вносите **только одно изменение за раз**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "__1FXprlL0Ne"
   },
   "source": [
    "Более полные и точные рецепты можете прочитать [здесь](https://github.com/puhsu/dl-hse/blob/main/week01-intro/lecture-best-practices.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QltavClgHIVx"
   },
   "outputs": [],
   "source": [
    "# теперь попробуйте поварьировать ваши гиперпараметры:\n",
    "# learning rate и lr scheduler, weight_decay, поменять аугментации\n",
    "# и, возможно, добавить какие-то изменения в модель"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b2IiIqFpMf_W"
   },
   "source": [
    "## Transfer Learning и Fine-Tune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yiOycRqMEk3x"
   },
   "source": [
    "Для многих прикладных задач не существует больших датасетов с хорошей разметкой. Поэтому распространенным приемом является тренировка на похожем, но большом датасете и доучивание сети на целевом.\n",
    "\n",
    "Такой прием называют **Transfer Learning** или **Fine-tuning**.\n",
    "\n",
    "В сверточных сетях для классификации выделяют две части:\n",
    "1. Тело сети (backbone) - это набор сверток и пулингов (convolutions and poolings)\n",
    "2. Голову (head) - это MLP (набор полносвязных слоев) после которых делается softmax и получаются вероятности разных классов.\n",
    "\n",
    "Вычислительно простым вариантом finetuning является переучивание головы сети."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X-dQYLDsDh4o"
   },
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "\n",
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "# кроме torchvision очень известен репозиторий pytorch-image-models\n",
    "# !pip install timm >> None\n",
    "# import timm\n",
    "# model = timm.create_model('resnet18', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k4f6-sQ9GryD"
   },
   "outputs": [],
   "source": [
    "# 10 - число наших классов\n",
    "model.fc = nn.Linear(in_features=512, out_features=10, bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZWB9hYj6GtCt"
   },
   "outputs": [],
   "source": [
    "# заморозим слои\n",
    "for param in model.parameters():\n",
    "  param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6gB-fxutNWqf"
   },
   "outputs": [],
   "source": [
    "# осталось лишь заметить, что пайплайн обучения уже написан - он хранится в model_pl\n",
    "# вам осталось его только запустить\n",
    "# проведите несколько экспериментов:\n",
    "# 1. Дообучите только голову\n",
    "# 2. Дообучите всю модель\n",
    "# 3. Поменяйте пайплайн аугментаций с вашего на тот, что вы нашли в репозитории модели"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPJCAzj4Sp2TFG7zrZQuzpv",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
