{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "YjEz7OtnPCkr"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3SMJbJwk-JFw"
   },
   "source": [
    "### Домашнее задание"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I5j41BOZrdr4"
   },
   "source": [
    "На основании функции по варианту необходимо:\n",
    "1. Построить nn.Module, в котором вы определите `forward`и `my_forward_backward`\n",
    "2. `forward` должен повторять функцию, выданную вам по варианту, `my_forward_backward` описывает проход по вычислителному графу, а также вычисление градиентов по этому графу с помощью backprop. Градиенты должны быть рассчитаны для параметров $w0, w1$, тензоры $x1, x2, x3$ считаются входными данными сети\n",
    "3. Необходимо удалять неиспользуемые тензоры, как это делает Pytorch\n",
    "4. Если какие-то узлы не нужны для вычисления результата, то вы не должны их вычислять в процессе backprop\n",
    "5. Необходимо построить визуализацию вычислительного графа\n",
    "\n",
    "Все материалы для выполнения задания можно найти в ноутбуках второго и третьего семинаров, а также в этом ноутбуке есть пример выполненного задания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LvQCO4gQPTR-"
   },
   "outputs": [],
   "source": [
    "def v4():\n",
    "    r1 = 3 * w0 + x3 * w1 + 1\n",
    "    r2 = x2 ** 3 * w1 / w0\n",
    "    r3 = w0 * (x3 + w1 ** 2)\n",
    "    return (r1 - r3) * x3 * r2 / r1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "mvqUaYAcHLhe"
   },
   "outputs": [],
   "source": [
    "def test_model_class(model_class):\n",
    "\n",
    "    model = model_class()\n",
    "\n",
    "    for _ in range(10):\n",
    "\n",
    "        x1, x2, x3 = torch.rand(3)\n",
    "\n",
    "        model.zero_grad()\n",
    "        y_torch = model(x1, x2, x3)\n",
    "        y_torch.backward()\n",
    "        grad_torch = model.w.grad.clone()\n",
    "\n",
    "        print(y_torch.clone().detach().numpy(), grad_torch.clone().numpy())\n",
    "\n",
    "        model.zero_grad()\n",
    "        with torch.no_grad():\n",
    "            y_manual = model.your_forward_backward(x1, x2, x3)\n",
    "        grad_manual = model.w.grad.clone()\n",
    "\n",
    "        print(y_manual.numpy(), grad_manual.numpy())\n",
    "        # print()\n",
    "\n",
    "        assert torch.allclose(y_manual, y_torch, rtol=5e-05, atol=1e-7)\n",
    "        assert torch.allclose(grad_manual, grad_torch, rtol=5e-05, atol=1e-7)\n",
    "\n",
    "    print('Tests completed successfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "qYoV5r2phrgP"
   },
   "outputs": [],
   "source": [
    "# Пример\n",
    "\n",
    "class ExampleGraph(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.w = nn.Parameter(torch.tensor([0.950, 0.288], dtype=torch.float32))\n",
    "\n",
    "    def forward(self, x1, x2, x3):\n",
    "        r1 = x3 * (x1 / x2 + self.w[1] / self.w[0])\n",
    "        r2 = x1 * x2 * x3 / (self.w[0] + self.w[1])\n",
    "        r3 = (self.w[0] * self.w[1]) ** 3.0\n",
    "        return (r1 + r2 + r3) / (x1 * r1 + r2 + r3)\n",
    "\n",
    "    def your_forward_backward(self, x1, x2, x3):\n",
    "        w0 = self.w[0]\n",
    "        w1 = self.w[1]\n",
    "\n",
    "        # forward\n",
    "        a0 = x1 / x2\n",
    "        a1 = w1 / w0\n",
    "        a2 = a0 + a1\n",
    "\n",
    "        a0 = a1 = None\n",
    "\n",
    "        a3 = x3 * a2 # r1\n",
    "\n",
    "        a2 = None\n",
    "\n",
    "        a4 = w0 + w1\n",
    "        a5 = x1 * x2\n",
    "\n",
    "        x2 = None\n",
    "\n",
    "        a6 = a5 * x3\n",
    "\n",
    "        a5 = None\n",
    "\n",
    "        a7 = a6 / a4 # r2\n",
    "\n",
    "        a8 = w0 * w1\n",
    "        a9 = a8 ** 3 # r3\n",
    "        a10 = a7 + a9 # r2 + r3\n",
    "\n",
    "        a7 = a9 = None\n",
    "\n",
    "        a11 = a10 + a3\n",
    "        a12 = x1 * a3\n",
    "\n",
    "        a3 = None\n",
    "\n",
    "        a13 = a12 + a10\n",
    "\n",
    "        a10 = a12 = None\n",
    "\n",
    "        a14 = a11 / a13\n",
    "\n",
    "        # backward\n",
    "        da14 = 1.0\n",
    "        da13 = da14 * ( - a11 / a13**2)\n",
    "\n",
    "        a11 = None\n",
    "\n",
    "        da12 = da13\n",
    "        da11 = da14 * (1 / a13)\n",
    "\n",
    "        a13 = da14 = None\n",
    "\n",
    "        da10 = da11 + da13\n",
    "\n",
    "        da13 = None\n",
    "\n",
    "        da9 = da10\n",
    "\n",
    "        da8 = da9 * 3 * a8 ** 2\n",
    "\n",
    "        da9 = a8 = None\n",
    "\n",
    "        da7 = da10\n",
    "\n",
    "        da10 = None\n",
    "\n",
    "        # da6 и da5 не нужны для вычисления итогового градиента\n",
    "\n",
    "        da4 = da7 * ( - a6 / a4 ** 2)\n",
    "\n",
    "        da7 = a6 = a4 = None\n",
    "\n",
    "        da3 = da11 + da12 * x1\n",
    "\n",
    "        da11 = da12 = x1 = None\n",
    "\n",
    "        da2 = da3 * x3\n",
    "\n",
    "        x3 = da3 = None\n",
    "\n",
    "        da1 = da2\n",
    "\n",
    "        da2 = None\n",
    "\n",
    "        dw1 = da8 * w0 + da4 + da1 / w0\n",
    "        dw0 = da8 * w1 + da1 * (- w1 / w0 ** 2) + da4\n",
    "\n",
    "        da1 = da4 = da8 = w0 = w1 = None\n",
    "\n",
    "        self.w.grad = torch.stack([dw0, dw1])\n",
    "\n",
    "        return a14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Graph(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.w = nn.Parameter(torch.tensor([0.950, 0.288], dtype=torch.float32))\n",
    "    \n",
    "    def forward(self, x1, x2, x3):\n",
    "        r1 = 3 * self.w[0] + x3 * self.w[1] + 1\n",
    "        r2 = x2 ** 3 * self.w[1] / self.w[0]\n",
    "        r3 = self.w[0] * (x3 + self.w[1] ** 2)\n",
    "        return (r1 - r3) * x3 * r2 / r1\n",
    "    \n",
    "    def your_forward_backward(self, x1, x2, x3):\n",
    "        w0 = self.w[0]\n",
    "        w1 = self.w[1]\n",
    "        \n",
    "        # forward\n",
    "        a0 = x2**3\n",
    "        \n",
    "        a1 = a0 * w1\n",
    "        a2 = w0 * 3\n",
    "        a3 = w1 * x3\n",
    "        a4 = w1 ** 2\n",
    "        \n",
    "        a5 = a1 / w0 # r2\n",
    "        a6 = a2 + a3\n",
    "        a7 = a4 + x3\n",
    "        \n",
    "        a8 = a6 + 1  # r1\n",
    "        a9 = w0 * a7 # r3\n",
    "        \n",
    "        a10 = a8 - a9\n",
    "        \n",
    "        a11 = a10 * x3\n",
    "        \n",
    "        a12 = a11 * a5\n",
    "        \n",
    "        a13 = a12 / a8\n",
    "        \n",
    "        # backward\n",
    "        \n",
    "        da13 = 1.0\n",
    "        \n",
    "        da12 = da13 / a8\n",
    "        \n",
    "        da11 = da12 * a5\n",
    "        \n",
    "        da10 = da11 * x3\n",
    "        \n",
    "        da9 = da10 * (-1.0)\n",
    "        \n",
    "        da8 = da10\n",
    "        \n",
    "        da7 = da9 * w0\n",
    "        \n",
    "        da6 = da8\n",
    "        \n",
    "        da5 = da12 * a11 \n",
    "        \n",
    "        da4 = da7  \n",
    "        \n",
    "        da3 = da6\n",
    "        \n",
    "        da2 = da6\n",
    "        \n",
    "        da1 = da5 / w0\n",
    "        \n",
    "        da0 = None\n",
    "        \n",
    "        dw1 = da1 * a0 + da3 * x3 + da4 * 2 * w1\n",
    "        \n",
    "        #da1 = da3 = da4 = a0 = x3 = w1 = None\n",
    "        \n",
    "        dw0 = da5 * ( -a1 / w0 ** 2) + da2 * 3 + da9 * a7 \n",
    "        \n",
    "        #da5 = da2 = da9 = a1 = a7 = w0 = None\n",
    "        \n",
    "        self.w.grad = torch.stack([dw0, dw1])\n",
    "        \n",
    "        return a13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ABjcjha16xtz",
    "outputId": "52214ff6-5636-4197-b64b-67e7257b5b85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04923805 [-0.05442992  0.16422787]\n",
      "0.04923805 [-0.0175566   0.17088513]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Здесь тестируется построенная вами модель\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtest_model_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mGraph\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[29], line 25\u001b[0m, in \u001b[0;36mtest_model_class\u001b[0;34m(model_class)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;66;03m# print()\u001b[39;00m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mallclose(y_manual, y_torch, rtol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5e-05\u001b[39m, atol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-7\u001b[39m)\n\u001b[0;32m---> 25\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mallclose(grad_manual, grad_torch, rtol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5e-05\u001b[39m, atol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-7\u001b[39m)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTests completed successfully!\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Здесь тестируется построенная вами модель\n",
    "test_model_class(Graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Graph()\n",
    "\n",
    "x1 = torch.randn(5)\n",
    "x2 = torch.randn(5)\n",
    "x3 = torch.randn(5)\n",
    "\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    (x1, x2, x3),\n",
    "    'graph.onnx',\n",
    "    opset_version=13,\n",
    "    export_params=True,\n",
    "    do_constant_folding=False,\n",
    "    input_names=['x1', 'x2', 'x3'],\n",
    "    output_names=['y'],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_HVl0_CaxsZp"
   },
   "outputs": [],
   "source": [
    "# А сюда вы должны вставить визуализацию графа"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](graph.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
